{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AND Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration=  0 cost=  0.920868\n",
      "iteration=  1000 cost=  0.545915\n",
      "iteration=  2000 cost=  0.405257\n",
      "iteration=  3000 cost=  0.326744\n",
      "iteration=  4000 cost=  0.276326\n",
      "iteration=  5000 cost=  0.240588\n",
      "iteration=  6000 cost=  0.213555\n",
      "iteration=  7000 cost=  0.192197\n",
      "iteration=  8000 cost=  0.174799\n",
      "iteration=  9000 cost=  0.160306\n",
      "iteration=  10000 cost=  0.148021\n",
      "iteration=  11000 cost=  0.137462\n",
      "iteration=  12000 cost=  0.128283\n",
      "Validating output for AND GATE\n",
      "[[ 0.0059016 ]\n",
      " [ 0.13516673]\n",
      " [ 0.1367977 ]\n",
      " [ 0.80665803]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "x=tf.placeholder(tf.float32,shape=[None,2])\n",
    "y=tf.placeholder(tf.float32,shape=[None,1])\n",
    "\n",
    "weights=tf.Variable(tf.random_normal([2,1]),dtype=tf.float32)\n",
    "bias=tf.Variable(tf.random_normal([1]),dtype=tf.float32)\n",
    "\n",
    "multiply1=tf.add(tf.matmul(x,weights),bias)\n",
    "z=tf.nn.sigmoid(multiply1)\n",
    "\n",
    "cost=tf.reduce_mean((y*tf.log(z)+(1-y)*tf.log(1-z))*-1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "\n",
    "inp=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "op=np.array([[0],[0],[0],[1]])\n",
    "with tf.Session() as sess:\n",
    "   \n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(12001):\n",
    "        res,_=sess.run([cost,optimizer],feed_dict={x:inp,y:op})\n",
    "        if i%1000==0:\n",
    "            print (\"iteration= \",i,\"cost= \",res)\n",
    "    print (\"Validating output for AND GATE\")\n",
    "    result=sess.run(z,feed_dict={x:inp})\n",
    "    print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OR Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration=  0 cost=  0.756081\n",
      "iteration=  1000 cost=  0.285347\n",
      "iteration=  2000 cost=  0.196347\n",
      "iteration=  3000 cost=  0.183937\n",
      "iteration=  4000 cost=  0.179822\n",
      "iteration=  5000 cost=  0.177876\n",
      "iteration=  6000 cost=  0.17677\n",
      "iteration=  7000 cost=  0.176067\n",
      "iteration=  8000 cost=  0.175585\n",
      "iteration=  9000 cost=  0.175236\n",
      "iteration=  10000 cost=  0.174973\n",
      "iteration=  11000 cost=  0.174768\n",
      "iteration=  12000 cost=  0.174605\n",
      "Validating output for OR GATE\n",
      "[[ 0.5       ]\n",
      " [ 0.99768102]\n",
      " [ 0.99706203]\n",
      " [ 0.99999321]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "x=tf.placeholder(tf.float32,shape=[None,2])\n",
    "y=tf.placeholder(tf.float32,shape=[None,1])\n",
    "\n",
    "weights=tf.Variable(tf.random_normal([2,1]),dtype=tf.float32)\n",
    "bias=tf.Variable(tf.random_normal([1]),dtype=tf.float32)\n",
    "\n",
    "multiply1=tf.multiply(tf.matmul(x,weights),bias)\n",
    "z=tf.nn.sigmoid(multiply1)\n",
    "\n",
    "cost=tf.reduce_mean((y*tf.log(z)+(1-y)*tf.log(1-z))*-1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "\n",
    "inp=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "op=np.array([[0],[1],[1],[1]])\n",
    "with tf.Session() as sess:\n",
    "   \n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(12001):\n",
    "        res,_=sess.run([cost,optimizer],feed_dict={x:inp,y:op})\n",
    "        if i%1000==0:\n",
    "            print (\"iteration= \",i,\"cost= \",res)\n",
    "    print (\"Validating output for OR GATE\")\n",
    "    result=sess.run(z,feed_dict={x:inp})\n",
    "    print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOT Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration=  0 cost=  0.702901\n",
      "iteration=  1000 cost=  0.365225\n",
      "iteration=  2000 cost=  0.236909\n",
      "iteration=  3000 cost=  0.170986\n",
      "iteration=  4000 cost=  0.132242\n",
      "iteration=  5000 cost=  0.10717\n",
      "iteration=  6000 cost=  0.0897799\n",
      "iteration=  7000 cost=  0.0770797\n",
      "iteration=  8000 cost=  0.0674314\n",
      "iteration=  9000 cost=  0.0598709\n",
      "iteration=  10000 cost=  0.0537968\n",
      "iteration=  11000 cost=  0.048816\n",
      "iteration=  12000 cost=  0.0446615\n",
      "Validating output for NOT GATE\n",
      "[[ 0.94756037]\n",
      " [ 0.03482977]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "x=tf.placeholder(tf.float32,shape=[None,1])\n",
    "y=tf.placeholder(tf.float32,shape=[None,1])\n",
    "\n",
    "weights=tf.Variable(tf.random_normal([1]),dtype=tf.float32)\n",
    "bias=tf.Variable(tf.random_normal([1]),dtype=tf.float32)\n",
    "\n",
    "multiply1=tf.add(tf.multiply(x,weights),bias)\n",
    "z=tf.nn.sigmoid(multiply1)\n",
    "\n",
    "cost=tf.reduce_mean((y*tf.log(z)+(1-y)*tf.log(1-z))*-1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "\n",
    "inp=np.array([[0],[1]])\n",
    "op=np.array([[1],[0]])\n",
    "with tf.Session() as sess:\n",
    "   \n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(12001):\n",
    "        res,_=sess.run([cost,optimizer],feed_dict={x:inp,y:op})\n",
    "        if i%1000==0:\n",
    "            print (\"iteration= \",i,\"cost= \",res)\n",
    "    print (\"Validating output for NOT GATE\")\n",
    "    result=sess.run(z,feed_dict={x:inp})\n",
    "    print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Shape:0\", shape=(2,), dtype=int32)\n",
      "iteration =  0 cost=  0.700802\n",
      "iteration =  1000 cost=  0.692693\n",
      "iteration =  2000 cost=  0.692566\n",
      "iteration =  3000 cost=  0.692435\n",
      "iteration =  4000 cost=  0.692297\n",
      "iteration =  5000 cost=  0.692145\n",
      "iteration =  6000 cost=  0.691976\n",
      "iteration =  7000 cost=  0.691785\n",
      "iteration =  8000 cost=  0.691565\n",
      "iteration =  9000 cost=  0.691308\n",
      "iteration =  10000 cost=  0.691006\n",
      "iteration =  11000 cost=  0.690645\n",
      "iteration =  12000 cost=  0.69021\n",
      "iteration =  13000 cost=  0.68968\n",
      "iteration =  14000 cost=  0.689029\n",
      "iteration =  15000 cost=  0.688222\n",
      "iteration =  16000 cost=  0.687214\n",
      "iteration =  17000 cost=  0.685945\n",
      "iteration =  18000 cost=  0.68434\n",
      "iteration =  19000 cost=  0.6823\n",
      "iteration =  20000 cost=  0.679706\n",
      "iteration =  21000 cost=  0.676409\n",
      "iteration =  22000 cost=  0.672242\n",
      "iteration =  23000 cost=  0.667024\n",
      "iteration =  24000 cost=  0.660583\n",
      "iteration =  25000 cost=  0.652785\n",
      "iteration =  26000 cost=  0.643571\n",
      "iteration =  27000 cost=  0.632989\n",
      "iteration =  28000 cost=  0.621204\n",
      "iteration =  29000 cost=  0.608483\n",
      "iteration =  30000 cost=  0.595147\n",
      "iteration =  31000 cost=  0.581518\n",
      "iteration =  32000 cost=  0.567868\n",
      "iteration =  33000 cost=  0.554405\n",
      "iteration =  34000 cost=  0.541271\n",
      "iteration =  35000 cost=  0.52856\n",
      "iteration =  36000 cost=  0.51634\n",
      "iteration =  37000 cost=  0.504668\n",
      "iteration =  38000 cost=  0.493595\n",
      "iteration =  39000 cost=  0.483168\n",
      "iteration =  40000 cost=  0.47342\n",
      "iteration =  41000 cost=  0.46437\n",
      "iteration =  42000 cost=  0.456018\n",
      "iteration =  43000 cost=  0.448348\n",
      "iteration =  44000 cost=  0.441332\n",
      "iteration =  45000 cost=  0.434932\n",
      "iteration =  46000 cost=  0.429105\n",
      "iteration =  47000 cost=  0.423803\n",
      "iteration =  48000 cost=  0.41898\n",
      "iteration =  49000 cost=  0.414593\n",
      "iteration =  50000 cost=  0.410597\n",
      "iteration =  51000 cost=  0.406954\n",
      "iteration =  52000 cost=  0.403628\n",
      "iteration =  53000 cost=  0.400587\n",
      "iteration =  54000 cost=  0.397801\n",
      "iteration =  55000 cost=  0.395243\n",
      "iteration =  56000 cost=  0.392892\n",
      "iteration =  57000 cost=  0.390725\n",
      "iteration =  58000 cost=  0.388724\n",
      "iteration =  59000 cost=  0.386874\n",
      "iteration =  60000 cost=  0.385159\n",
      "iteration =  61000 cost=  0.383567\n",
      "iteration =  62000 cost=  0.382085\n",
      "iteration =  63000 cost=  0.380705\n",
      "iteration =  64000 cost=  0.379417\n",
      "iteration =  65000 cost=  0.378212\n",
      "iteration =  66000 cost=  0.377083\n",
      "iteration =  67000 cost=  0.376025\n",
      "iteration =  68000 cost=  0.37503\n",
      "iteration =  69000 cost=  0.374094\n",
      "iteration =  70000 cost=  0.373213\n",
      "iteration =  71000 cost=  0.372381\n",
      "iteration =  72000 cost=  0.371595\n",
      "iteration =  73000 cost=  0.370852\n",
      "iteration =  74000 cost=  0.370148\n",
      "iteration =  75000 cost=  0.36948\n",
      "iteration =  76000 cost=  0.368846\n",
      "iteration =  77000 cost=  0.368244\n",
      "iteration =  78000 cost=  0.367671\n",
      "iteration =  79000 cost=  0.367125\n",
      "iteration =  80000 cost=  0.366604\n",
      "iteration =  81000 cost=  0.366108\n",
      "iteration =  82000 cost=  0.365634\n",
      "iteration =  83000 cost=  0.365181\n",
      "iteration =  84000 cost=  0.364747\n",
      "iteration =  85000 cost=  0.364332\n",
      "iteration =  86000 cost=  0.363934\n",
      "iteration =  87000 cost=  0.363553\n",
      "iteration =  88000 cost=  0.363187\n",
      "iteration =  89000 cost=  0.362835\n",
      "iteration =  90000 cost=  0.362497\n",
      "iteration =  91000 cost=  0.362172\n",
      "iteration =  92000 cost=  0.36186\n",
      "iteration =  93000 cost=  0.361558\n",
      "iteration =  94000 cost=  0.361268\n",
      "iteration =  95000 cost=  0.360989\n",
      "iteration =  96000 cost=  0.360718\n",
      "iteration =  97000 cost=  0.360458\n",
      "iteration =  98000 cost=  0.360207\n",
      "iteration =  99000 cost=  0.359963\n",
      "Validating output for XOR GATE\n",
      "[[ 0.02269967]\n",
      " [ 0.98911208]\n",
      " [ 0.4931615 ]\n",
      " [ 0.50246298]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "x=tf.placeholder(tf.float32,shape=[None,2])\n",
    "y=tf.placeholder(tf.float32,shape=[None,1])\n",
    "\n",
    "#weights=tf.Variable(tf.random_normal([2,1]),dtype=tf.float32)\n",
    "#bias=tf.Variable(tf.random_normal([1]),dtype=tf.float32)\n",
    "\n",
    "#multiply1=tf.add(tf.matmul(x,weights),bias)\n",
    "#z=tf.nn.sigmoid(multiply1)\n",
    "\n",
    "Theta1 = tf.Variable(tf.random_uniform([2,2], -1, 1), name=\"Theta1\")\n",
    "Theta2 = tf.Variable(tf.random_uniform([2,1], -1, 1), name=\"Theta2\")\n",
    "Bias1 = tf.Variable(tf.zeros([2]), name=\"Bias1\")\n",
    "Bias2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")\n",
    "A2 = tf.sigmoid(tf.matmul(x, Theta1) + Bias1)\n",
    "z = tf.sigmoid(tf.matmul(A2, Theta2) + Bias2)\n",
    "print(tf.shape(A2))    \n",
    "cost=tf.reduce_mean((y*tf.log(z)+(1-y)*tf.log(1-z))*-1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "\n",
    "inp=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "op=np.array([[0],[1],[1],[0]])\n",
    "with tf.Session() as sess:\n",
    "   \n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(100000):\n",
    "        res,_=sess.run([cost,optimizer],feed_dict={x:inp,y:op})\n",
    "        if i%1000==0:\n",
    "            print (\"iteration = \",i,\"cost= \",res)\n",
    "    print (\"Validating output for XOR GATE\")\n",
    "    result=sess.run(z,feed_dict={x:inp})\n",
    "    print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
